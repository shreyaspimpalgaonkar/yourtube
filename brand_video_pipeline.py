#!/usr/bin/env -S uv run
# /// script
# requires-python = ">=3.10"
# dependencies = ["moviepy>=2.0", "google-genai", "pillow"]
# ///
"""
Brand Video Pipeline: Extract frames, add logo with Nano Banana, 
interpolate with Veo 3.1, and stitch back together.
"""

import os
import time
import io
from pathlib import Path
from moviepy import VideoFileClip
from google import genai
from google.genai import types
from PIL import Image

# Configuration
VIDEO_FILE = "office.mp4"
OUTPUT_DIR = "branded_video_output"

# Jim segment: 0:16 to 0:20 (in seconds)
START_TIME = 16
END_TIME = 20

# Brand to add
BRAND_NAME = "Athlead"
BRAND_PROMPT = """
Using this image, add an Athlead logo to Jim's shirt or visible clothing area.
Athlead is a sports marketing company - the logo should look like a professional 
sports agency logo with the text "Athlead" visible. Make it look natural and 
realistic, like an embroidered or printed logo on his clothing. Keep everything 
else in the image exactly the same - his face, expression, the background, and 
all other details should remain unchanged.
"""


def extract_frame(video_path: str, timestamp: float) -> Image.Image:
    """Extract a single frame from video at the given timestamp."""
    video = VideoFileClip(video_path)
    frame = video.get_frame(timestamp)
    video.close()
    return Image.fromarray(frame)


def extract_frames_from_segment(video_path: str, start: float, end: float, fps: int = 3) -> list[tuple[float, Image.Image]]:
    """Extract frames from a video segment at specified fps."""
    print(f"üì∏ Extracting frames from {start}s to {end}s at {fps} fps...")
    
    video = VideoFileClip(video_path)
    frames = []
    
    duration = end - start
    num_frames = int(duration * fps)
    
    for i in range(num_frames + 1):
        timestamp = start + (i / fps)
        if timestamp <= end:
            frame = video.get_frame(timestamp)
            frames.append((timestamp, Image.fromarray(frame)))
            print(f"   Extracted frame at {timestamp:.2f}s")
    
    video.close()
    print(f"   Total frames extracted: {len(frames)}")
    return frames


def add_logo_with_nano_banana(image: Image.Image, prompt: str) -> Image.Image:
    """Use Gemini Nano Banana to edit the image with the given prompt."""
    client = genai.Client()
    
    # Convert PIL image to bytes
    img_byte_arr = io.BytesIO()
    image.save(img_byte_arr, format='PNG')
    img_bytes = img_byte_arr.getvalue()
    
    # Create the image part
    image_part = types.Part.from_bytes(
        data=img_bytes,
        mime_type='image/png',
    )
    
    # Generate with Gemini 3 Pro image editing
    response = client.models.generate_content(
        model="gemini-3-pro-image-preview",
        contents=[image_part, prompt],
    )
    
    # Extract the generated image from response
    for part in response.parts:
        if part.inline_data is not None:
            image_data = part.inline_data.data
            edited_image = Image.open(io.BytesIO(image_data))
            return edited_image
        elif part.text is not None:
            print(f"   üìù Gemini note: {part.text[:100]}...")
    
    raise ValueError("No image was generated by Nano Banana")


def interpolate_with_veo(first_frame: Image.Image, last_frame: Image.Image, prompt: str) -> str:
    """Use Veo 3.1 to interpolate between first and last frames."""
    print("üé¨ Starting Veo 3.1 interpolation...")
    
    client = genai.Client()
    
    # Convert first frame to bytes
    first_bytes = io.BytesIO()
    first_frame.save(first_bytes, format='PNG')
    first_image = types.Image(image_bytes=first_bytes.getvalue(), mime_type="image/png")
    
    # Convert last frame to bytes  
    last_bytes = io.BytesIO()
    last_frame.save(last_bytes, format='PNG')
    last_image = types.Image(image_bytes=last_bytes.getvalue(), mime_type="image/png")
    
    # Generate video with Veo 3.1 using first and last frame interpolation
    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview",
        prompt=prompt,
        image=first_image,
        config=types.GenerateVideosConfig(
            last_frame=last_image,
            duration_seconds="8",
            aspect_ratio="16:9",
        ),
    )
    
    # Poll until video is ready
    print("   ‚è≥ Waiting for video generation (this may take a few minutes)...")
    poll_count = 0
    while not operation.done:
        poll_count += 1
        print(f"   Polling... ({poll_count * 10}s elapsed)")
        time.sleep(10)
        operation = client.operations.get(operation)
    
    print("   ‚úÖ Video generation complete!")
    
    # Debug: print the response structure
    print(f"   Response: {operation.response}")
    
    # Check if we have generated videos
    if operation.response is None:
        print("   ‚ö†Ô∏è Response is None - video may have been blocked by safety filters")
        return None
    
    if not hasattr(operation.response, 'generated_videos') or not operation.response.generated_videos:
        print(f"   ‚ö†Ô∏è No generated videos in response")
        print(f"   Full response: {operation.response}")
        return None
    
    # Download the video
    video = operation.response.generated_videos[0]
    client.files.download(file=video.video)
    
    output_path = Path(OUTPUT_DIR) / "interpolated_video.mp4"
    video.video.save(str(output_path))
    
    return str(output_path)


def main():
    print("=" * 70)
    print("üé¨ BRAND VIDEO PIPELINE: Add Athlead Logo to Jim's Segment")
    print("=" * 70)
    
    # Check video exists
    if not Path(VIDEO_FILE).exists():
        print(f"‚ùå Video not found: {VIDEO_FILE}")
        return
    
    # Create output directory
    Path(OUTPUT_DIR).mkdir(exist_ok=True)
    
    # Step 1: Extract first and last frames from the segment
    print(f"\nüìç Segment: {START_TIME}s to {END_TIME}s (Jim)")
    
    print("\n[Step 1/4] Extracting first and last frames...")
    first_frame = extract_frame(VIDEO_FILE, START_TIME)
    last_frame = extract_frame(VIDEO_FILE, END_TIME)
    
    # Save original frames
    first_frame.save(Path(OUTPUT_DIR) / "original_first_frame.png")
    last_frame.save(Path(OUTPUT_DIR) / "original_last_frame.png")
    print(f"   Saved original frames to {OUTPUT_DIR}/")
    
    # Step 2: Edit frames with Nano Banana
    print("\n[Step 2/4] Adding Athlead logo with Nano Banana...")
    
    print("   Editing first frame...")
    edited_first = add_logo_with_nano_banana(first_frame, BRAND_PROMPT)
    edited_first.save(Path(OUTPUT_DIR) / "edited_first_frame.png")
    print("   ‚úÖ First frame edited")
    
    print("   Editing last frame...")
    edited_last = add_logo_with_nano_banana(last_frame, BRAND_PROMPT)
    edited_last.save(Path(OUTPUT_DIR) / "edited_last_frame.png")
    print("   ‚úÖ Last frame edited")
    
    # Step 3: Interpolate with Veo 3.1
    print("\n[Step 3/4] Interpolating with Veo 3.1...")
    
    interpolation_prompt = f"""
    A smooth, cinematic video transition. Jim from The Office is in an office 
    environment, wearing clothing with an {BRAND_NAME} logo visible. The scene 
    should maintain the mockumentary style of The Office with natural lighting 
    and realistic office environment. The motion should be natural and fluid, 
    transitioning smoothly between the start and end positions.
    """
    
    video_path = interpolate_with_veo(edited_first, edited_last, interpolation_prompt)
    
    # Step 4: Done!
    print("\n[Step 4/4] Pipeline complete!")
    
    if video_path is None:
        print("\n‚ö†Ô∏è Video interpolation failed or was blocked.")
        print("   However, the edited frames are ready for manual video creation.")
    print(f"\n‚úÖ Output files in '{OUTPUT_DIR}/':")
    print(f"   - original_first_frame.png")
    print(f"   - original_last_frame.png")
    print(f"   - edited_first_frame.png")
    print(f"   - edited_last_frame.png")
    if video_path:
        print(f"   - interpolated_video.mp4")
        print("\nüéâ Done! The branded video is ready.")
    else:
        print("\nüéâ Edited frames are ready! Use them with video editing software.")


if __name__ == "__main__":
    main()

